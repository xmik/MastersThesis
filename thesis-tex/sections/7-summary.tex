\section{Conclusions}
\textit{A summary of the whole study is demonstrated in this chapter.}
\\

The aim of this study was to deploy a Kubernetes cluster in a production environment, on AWS cloud, to use multiple deployment methods, and to compare them. Two deployment methods were chosen: using \textit{kops} and using \textit{eksctl}. They were described in the chapter: \ref{3-methods}. Both of them facilitate the deployment tasks to a tremendous extent.

Production environment was defined in the \ref{2-prod-req} chapter and it was stated, that several requirements must be met in order to be able to name a deployment production-ready. Some ideas of how to satisfy the requirements were described in the \ref{prep-prod} chapter. Obviously, there are more such requirements and this study does not exhaust this topic. Then, a decision was made on which production environment requirements should be satisfied in this study. 9 production environment requirements were selected.

Next, the development environment and essential tools were chosen. The following \ref{5-depl} chapter described in detail how the Kubernetes clusters were deployed, using the two methods. The cluster operations were: create, test and delete. They were automated to the point, so that they can be run using a single \textit{Bash} command. All the commands needed to configure the cluster and to satisfy all the production requirements were presented. Additionally, the study was supposed to have a practical approach, thus several encountered problems and solutions to them were described. This chapter ended with general guidelines on Kubernetes clusters troubleshooting.

Then, the two methods were compared using several comparison criteria. The criteria contained, among others: time, cost and the verdict whether a deployment method can satisfy all the production environment requirements. This comparison chapter, \ref{6-comp}, was based on the whole empirical work and experiments, described earlier. The conclusion was that each method can be used for different use cases. For example: \textit{kops} allows more configuration, whereas \textit{eksctl} is easier to configure. The method which was deemed faster (in relation to cluster operations) and cheaper was \textit{kops}.

\subsection{Lessons learned}

Writing this work allowed to \textbf{gather some knowledge about Kubernetes, its components and architecture}. The best documentation sources happen to be the official Kubernetes, \textit{AWS EKS}, \textit{kops} and \textit{eksctl} websites. But, there are also many blog posts available providing tutorials on how to use \textit{kops} or \textit{eksctl}. However, not all the expertise can be achieved just by reading. The many cluster deployments were very helpful to build an intuition of how a Kubernetes cluster works, what are the potential problems and how to deal with them. For instance, there was an unexpected problem, when deploying with \textit{eksctl}. This problem was caused by \textit{AWS EKS} hard limits of number of  allowed pods on a particular EC2 instance type. Many problems were described in this work and solutions for them were provided too.

Furthermore, it was experienced, that \textbf{one should aspire to satisfy the requirements one by one}. This helps to isolate the failure - meaning: when there is some issue, the scope of the issue is smaller. Secondly, working on one requirement at a time, makes it easier to later describe how the requirement was fulfilled.

Next, \textbf{the automation requirement turned out to be extremely vital}. Thanks to the cluster operations being automated, one could recreate a cluster any number of times and, each time, expect the same results. One could then rely on the work already performed and build upon its results. Automation enables us to have easily reproducible environments and facilitates the experiments repetition.

Overall, this work was an opportunity to immerse into the Kubernetes world and to get to know its possibilities and problems. The nice aspect of such work was that this kind of technology is still fresh and that the history of the programs described in this work happens now (e.g. through the pull requests on \textit{Github.com}). This also has its downsides, for example a bug may just have been discovered and a solution has not yet been released.

\subsection{Future work potential}

There is a great deal of improvements which can be applied while deploying a Kubernetes cluster using various methods and trying to compare them. Probably the most obvious way to make such a comparison better, is to \textbf{add more deployment methods}. Kubernetes can be deployed in the cloud, thus other managed services like: Azure Kubernetes Service (AKS) or Google Kubernetes Engine (GKE) could be tried. But there are also many custom solutions available, e.g. using Terraform, described in the chapter: \ref{3-methods}.

Secondly, in this work 9 production environment requirements were considered. Yet, many more could be. Ideas for \textbf{additional requirements are}: cluster live upgrades, cluster live reconfiguration, dealing with persistent data, obeying some country laws (concerning for example how long some data should be kept) and more.

The third aspect is, that \textbf{every administrator or every company has their own views on how to satisfy each of the requirements}. For some people whitelisting one IP address to have access to a Kubernetes API server is enough, while the other could demand to keep all master and worker nodes in a private network and use a bastion host. The same applies to other requirements. Potentially, the automation requirement may have been met by deploying some CI server, creating a pipeline which would create, test and then delete a testing cluster and only then, another pipeline could have been run to deploy to a production environment. Besides, there are many tools listed in the \ref{2-prod-req} chapter, like Grafana, Graylog, Logstash, which could have been applied.

The next thing is that, in order to decide which method is the best for a production deployment, \textbf{a production load could be simulated}. This could be accomplished either by running experiments on e.g. 100 EC2 worker nodes or conducting a survey among Kubernetes administrators (or companies using Kubernetes) and asking questions about the long running clusters. Such experiments could lead to different problems, than ones described in this study. There could be some AWS hard limits reached on the allowed number of EC2 instances or perhaps there could be a problem with not fast enough data transfer.

This leads to the fifth idea, namely, the \textbf{comparison criteria could be performance oriented}. In such a case, a chosen test application could have had needs for special resources, maybe running some Machine Learning tasks, demanding access to GPU, lighting-fast data transfer and tiny latencies. Then, the cluster providing the most efficient resources would have been a winner. Choosing this approach, one could also compare the results with the existing papers like the one paper which evaluates a performance of containers running on Managed Kubernetes Services \cite{article-managed}.

To sum up, there is a wide variety of the potential future work. Kubernetes is a very popular platform, thus it can be hoped that more academic papers, regarding this topic, will appear. For now, Kubernetes is still evolving and many helpful tools (like \textit{kops} and \textit{eksctl}) are being worked on.

% https://github.com/vmware-tanzu/sonobuoy
% https://github.com/cncf/k8s-conformance/blob/master/instructions.md
% eks with fargate
% tests - https://kubernetes.io/docs/setup/best-practices/node-conformance/
% CloudWatch alarms. The potential alarms could warn the Kubernetes cluster administrator that for example:
% \begin{itemize}
%  \item the AWS resources cost more than 20 GBP,
% \item there is too much CPU usage (in percentage units).
% \end{itemize}

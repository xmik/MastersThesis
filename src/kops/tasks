#!/bin/bash

set -e

# any environment variable containing non-numeric characters should be unset,
# because it impedes the "kops create cluster" command
unset OS_PASSWORD

export K8S_EXP_REGION="eu-west-1"
# there will be 1 s3 bucket to keep k8s clusters config, for many clusters
# (for many environments)
export K8S_EXP_KOPS_S3_BUCKET="k8s-kops-for-masters-thesis.k8s.local"
export K8S_EXP_VELERO_S3_BUCKET="${K8S_EXP_KOPS_S3_BUCKET}"

if [[ "${K8S_EXP_ENVIRONMENT}" != "testing" ]] && [[ "${K8S_EXP_ENVIRONMENT}" != "production" ]]; then
  echo "Error: K8S_EXP_ENVIRONMENT should be set to testing or production"
  exit 1
fi

export K8S_EXP_CLUSTER_NAME="${K8S_EXP_ENVIRONMENT}.${K8S_EXP_KOPS_S3_BUCKET}"

function create_s3_bucket() {
  local bucket_name=$1
  local region=$2

  if aws s3api list-buckets | jq '.Buckets[]["Name"]' | grep ${bucket_name} >/dev/null; then
    echo "S3 Bucket already exists"
  else
    echo "Creating S3 Bucket: ${bucket_name}"
    set -x
    aws s3api create-bucket --bucket ${bucket_name} --region ${region} --create-bucket-configuration LocationConstraint=${region}
    # enable s3 bucket versioning.
    # strongly recommended in: https://aws.amazon.com/blogs/compute/kubernetes-clusters-aws-kops/
    # https://kops.sigs.k8s.io/getting_started/aws
    aws s3api put-bucket-versioning --bucket ${bucket_name} --versioning-configuration Status=Enabled
    # enable s3 default encryption (AES-256, SSE-S3)
    # https://kops.sigs.k8s.io/getting_started/aws
    aws s3api put-bucket-encryption --bucket ${bucket_name} --server-side-encryption-configuration '{"Rules":[{"ApplyServerSideEncryptionByDefault":{"SSEAlgorithm":"AES256"}}]}'
    set +x
    echo "Success"
  fi
}

command="$1"
case "${command}" in
    _gen_config_minimal)
        # this task generates the minimal configuration

        cluster_name="kops.minimal.k8s.local"
        create_s3_bucket ${K8S_EXP_KOPS_S3_BUCKET} ${K8S_EXP_REGION}
        set -x
        # generate a cluster configuration
        kops create cluster --state "s3://${K8S_EXP_KOPS_S3_BUCKET}" \
          --cloud=aws --cloud-labels="deployment=kops-${K8S_EXP_ENVIRONMENT}" \
          --kubernetes-version=1.16.9 \
          --master-zones="eu-west-1a" --master-count=1 --master-size=t2.micro \
          --zones=eu-west-1a --node-count=1 --node-size=t2.micro \
          ${cluster_name}
        # export the configuration to a YAML file
        kops get -o yaml --name   ${cluster_name} --state "s3://${K8S_EXP_KOPS_S3_BUCKET}" > cluster-minimal.kops-tmpl.yaml
        # now create cluster-minimal.tmpl.yaml with the following steps:
        # * replace string: testing with string: ${K8S_EXP_ENVIRONMENT}
        # * replace string: kops.minimal.k8s.local with string: ${K8S_EXP_CLUSTER_NAME}
        # * replace string: k8s-kops-for-masters-thesis.k8s.local with string: ${K8S_EXP_KOPS_S3_BUCKET}
        ;;
    _gen_config_full)
        # this task generates the full configuration

        cluster_name="${K8S_EXP_CLUSTER_NAME}"
        create_s3_bucket ${K8S_EXP_KOPS_S3_BUCKET} ${K8S_EXP_REGION}
        set -x
        # generate a cluster configuration
        my_ip=$(curl https://ipinfo.io/ip 2>/dev/null)
        kops create cluster --state "s3://${K8S_EXP_KOPS_S3_BUCKET}" \
          --cloud=aws --cloud-labels="deployment=kops-${K8S_EXP_ENVIRONMENT}" \
          --kubernetes-version=1.16.9 \
          --master-zones="eu-west-1a,eu-west-1b,eu-west-1c" --master-count=3 --master-size=t2.micro \
          --zones=eu-west-1a --node-count=1 --node-size=t2.micro \
          --ssh-access=${my_ip}/32 \
          ${cluster_name}
        # export the configuration to a YAML file
        kops get -o yaml --name   ${cluster_name} --state "s3://${K8S_EXP_KOPS_S3_BUCKET}" > cluster.kops-tmpl.yaml
        # now create cluster.tmpl.yaml with the following steps:
        # * set kubernetesApiAccess
        # * replace any ip with ${my_ip}/32 (this should concern sshAccess and kubernetesApiAccess)
        # * replace string: testing with string: ${K8S_EXP_ENVIRONMENT}
        # * replace string: kops.minimal.k8s.local with string: ${K8S_EXP_CLUSTER_NAME}
        # * replace string: k8s-kops-for-masters-thesis.k8s.local with string: ${K8S_EXP_KOPS_S3_BUCKET}
        # * add additionalPolicies
        # * set maxSize: 2 (or sth bigger than 1) to allow autoscaling of worker nodes
        # * also for autoscaling, set cloudLabels for worker nodes
        # spec:
        #   cloudLabels:
        #     service: k8s_node
        #     k8s.io/cluster-autoscaler/enabled: ""
        #     k8s.io/cluster-autoscaler/testing.k8s-kops-for-masters-thesis.k8s.local: ""
        ;;
    _create)
        # this task deploys a cluster
        template_file="cluster.tmpl.yaml"
        config_file="cluster.yaml"

        my_ip=$(curl https://ipinfo.io/ip 2>/dev/null)
        sed "s/\${K8S_EXP_CLUSTER_NAME}/${K8S_EXP_CLUSTER_NAME}/" ${template_file} > cluster1.yaml
        sed "s/\${K8S_EXP_KOPS_S3_BUCKET}/${K8S_EXP_KOPS_S3_BUCKET}/" cluster1.yaml > cluster2.yaml
        sed "s/\${K8S_EXP_ENVIRONMENT}/${K8S_EXP_ENVIRONMENT}/" cluster2.yaml > cluster3.yaml
        sed "s'\${my_ip}'${my_ip}/32'" cluster3.yaml > ${config_file}
        rm cluster1.yaml cluster2.yaml cluster3.yaml
        echo "Generated ${config_file}"

        # deploy the cluster; --force is needed if "kops create cluster" was not run before
        set -x
        kops replace -f ${config_file} --name ${K8S_EXP_CLUSTER_NAME} --state "s3://${K8S_EXP_KOPS_S3_BUCKET}" --force
        kops create secret --name ${K8S_EXP_CLUSTER_NAME} --state "s3://${K8S_EXP_KOPS_S3_BUCKET}" sshpublickey admin -i ~/.ssh/id_rsa.pub
        set +x

        # print date, so that end user can expect how much longer to wait
        date
        kops update cluster ${K8S_EXP_CLUSTER_NAME} --state "s3://${K8S_EXP_KOPS_S3_BUCKET}" --yes
        # wait for the deployment to finish
        date
        while [ 1 ]; do
          kops validate cluster ${K8S_EXP_CLUSTER_NAME} --state "s3://${K8S_EXP_KOPS_S3_BUCKET}" && break || sleep 30
        done;
        date
        ;;
    _enable_logging)
        date
        set -x
        # enable logging to AWS CloudWatch
        # https://awscli.amazonaws.com/v2/documentation/api/latest/reference/logs/create-log-group.html
        aws logs create-log-group --log-group-name k8s-kops-${K8S_EXP_ENVIRONMENT}
        helm install "kube2iam" --namespace="default" --wait --atomic --set rbac.create=true stable/kube2iam
        helm repo add incubator https://kubernetes-charts-incubator.storage.googleapis.com
        helm install "fluentd-cloudwatch" --namespace="default" --wait --atomic --set awsRegion=${K8S_EXP_REGION},rbac.create=true,logGroupName=k8s-kops-${K8S_EXP_ENVIRONMENT} incubator/fluentd-cloudwatch
        date
        ;;
    _list_instances)
        aws ec2 describe-instances --filters "Name=tag-key,Values=deployment" --query "Reservations[*].Instances[*].{PublicIP:PublicIpAddress,Name:Tags[?Key=='Name']|[0].Value,Status:State.Name}"
        ;;
    _enable_as)
        set -x
        sed "s/\${CLUSTER_NAME}/${K8S_EXP_CLUSTER_NAME}/" ../as/cluster-autoscaler-autodiscover.tmpl.yaml > cluster-autoscaler-autodiscover.yaml
        kubectl apply -f cluster-autoscaler-autodiscover.yaml
        ;;
    _install_velero_cli)
        wget -O /tmp/velero.tar.gz https://github.com/vmware-tanzu/velero/releases/download/v1.4.0/velero-v1.4.0-linux-amd64.tar.gz
        cd /tmp
        tar -xvf velero.tar.gz
        chmod +x velero/velero
        sudo mv velero/velero /usr/local/bin/velero
        ;;
    _enable_velero)
        create_s3_bucket ${K8S_EXP_VELERO_S3_BUCKET} ${K8S_EXP_REGION}
        set -x
        kubectl create namespace velero
        helm repo add vmware-tanzu https://vmware-tanzu.github.io/helm-charts
        helm install velero --namespace velero -f ${PWD}/../velero/velero-chart-values.yaml \
          --set configuration.backupStorageLocation.bucket=${K8S_EXP_VELERO_S3_BUCKET} \
          --set configuration.backupStorageLocation.prefix=${K8S_EXP_ENVIRONMENT} \
          --set configuration.backupStorageLocation.config.region=${K8S_EXP_REGION} \
          --set-file credentials.secretContents.cloud=credentials-velero \
          --wait --atomic vmware-tanzu/velero
        ;;
    _test)
        set -x
        time kops validate cluster ${K8S_EXP_CLUSTER_NAME} --state "s3://${K8S_EXP_KOPS_S3_BUCKET}"
        cd ../tests
        time bats tests.bats
        cd ../kops
        ;;
    _delete)
        # print date, so that end user can expect how much longer to wait
        date
        set -x
        time kops delete cluster --name ${K8S_EXP_CLUSTER_NAME} --state "s3://${K8S_EXP_KOPS_S3_BUCKET}" --yes
        aws logs delete-log-group --log-group-name k8s-kops-${K8S_EXP_ENVIRONMENT}
        ;;
    _clean)
        # print date, so that end user can expect how much longer to wait
        date
        set -x
        # TODO: delete - delete velero users and s3 buckets; and users keys? aws iam delete-user --user-name Bob
        ;;
    *)
        echo "Invalid command: '${command}'"
        exit 1
        ;;
esac
